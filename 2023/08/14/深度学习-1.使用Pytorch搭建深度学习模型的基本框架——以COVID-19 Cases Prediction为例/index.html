

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="https://s2.loli.net/2023/07/15/AhaZCquL51QoPpk.png">
  <link rel="icon" href="https://s2.loli.net/2023/07/15/AhaZCquL51QoPpk.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="喵老师">
  <meta name="keywords" content="">
  
    <meta name="description" content="本节主要介绍使用Pytorch完成深度学习模型训练的基本框架及算法步骤。">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习-1.使用Pytorch搭建深度学习模型的基本框架——以COVID-19 Cases Prediction为例">
<meta property="og:url" content="http://example.com/2023/08/14/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-1.%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BA%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A1%86%E6%9E%B6%E2%80%94%E2%80%94%E4%BB%A5COVID-19%20Cases%20Prediction%E4%B8%BA%E4%BE%8B/index.html">
<meta property="og:site_name" content="喵老师&#39;s Blog">
<meta property="og:description" content="本节主要介绍使用Pytorch完成深度学习模型训练的基本框架及算法步骤。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s2.loli.net/2023/07/26/tDhLZgxV4HaIizX.jpg">
<meta property="article:published_time" content="2023-08-14T05:43:29.000Z">
<meta property="article:modified_time" content="2023-08-15T17:32:44.757Z">
<meta property="article:author" content="喵老师">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://s2.loli.net/2023/07/26/tDhLZgxV4HaIizX.jpg">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>深度学习-1.使用Pytorch搭建深度学习模型的基本框架——以COVID-19 Cases Prediction为例 - 喵老师&#39;s Blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.5","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="喵老师's Blog" type="application/atom+xml">

<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>喵老师&#39;s Blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/Daily/" target="_self">
                <i class="iconfont icon-music"></i>
                <span>日常</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('https://s2.loli.net/2023/07/17/Myx8RtuvNLKFgiZ.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="深度学习-1.使用Pytorch搭建深度学习模型的基本框架——以COVID-19 Cases Prediction为例"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2023-08-14 13:43" pubdate>
          2023年8月14日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          13k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          111 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">深度学习-1.使用Pytorch搭建深度学习模型的基本框架——以COVID-19 Cases Prediction为例</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="使用pytorch搭建深度学习模型的基本框架">使用Pytorch搭建深度学习模型的基本框架</h1>
<p>  自2012年Alexnet在Imagenet图像分类竞赛中一鸣惊人，以神经网络算法为主体的深度学习技术在人工智能领域兴起，而后诸如卷积神经网络(CNN)，残差网络(Resnet)，生成式对抗网络(GAN)，自注意力模型(Transformer)等众多性能强大的算法模型被提出，使得人工智能领域的研究与应用进入了一个蓬勃发展的阶段。2016年，DeepMind推出围棋人工智能AlphaGo，其以4:1战胜围棋世界冠军李世石，让世人认识到了深度学习技术的强大。2023年，基于Transformer的LLM模型ChatGPT横空出世，这场来自AI领域的技术革命第一次距离我们如此之近。无人知晓深度学习未来能给人类世界带来多大的变革，它能否最终实现强人工智能，带领我们进入科幻电影中的世界，但至少目前，深度学习仍牢牢占据学术与工业界研究的主流。<br>
  在众多用于实现深度学习技术的框架中，Pytorch与TensorFlow目前被使用得最为广泛，而Pyotrch以其简洁的语法与强大的生态颇受学者的青睐，成为目前学术研究最流行的深度学习框架，本节会以COVID-19
Cases为例，使用Pytorch搭建一个深度学习模型。这是一个非常简单的回归任务，在完成这个任务的过程中，我们将会了解使用Pytorch搭建深度学习模型的流程、各种函数的作用以及训练模型的步骤。</p>
<h2 id="task-description">Task Description</h2>
<ul>
<li><p><strong>Objectives</strong></p>
<ul>
<li>Solve a regression problem with deep neural networks(DNN)<br>
</li>
<li>Understand basic DNN training steps.</li>
<li>Get familiar with PyTorch.</li>
</ul></li>
<li><p><strong>Task</strong><br>
  <strong>COVID-19 Cases Prediction:</strong> Given survey results in
the past 5 days in a specific states in U.S., then predict the
percentage of new tested positive cases in the 5th day.</p></li>
<li><p><strong>Data</strong></p>
<ul>
<li>Training Data: 2699 samples<br>
</li>
<li>Testing Data: 1078 samples<br>
</li>
<li>Feature Infactors(117):
<ul>
<li>States(37, encoded to one-hot vector)</li>
<li>COVID-like illness(4*5)
<ul>
<li>cli、ili ...</li>
</ul></li>
<li>Behavior Indicators(8*5)
<ul>
<li>wearing_mask、travel_outside_state ...</li>
</ul></li>
<li>Mental Health Indicators(3*5)
<ul>
<li>anxious、depressed ...</li>
</ul></li>
<li>Tested Positive Cases(1*5)
<ul>
<li>tested_positive(<strong>this is what we want to
predict</strong>)</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<h2 id="download-data">Download Data</h2>
<p>  本案例的数据集来自于Kaggle，可以访问以下网站下载数据集.</p>
<ul>
<li>Data Source:
https://www.kaggle.com/competitions/ml2022spring-hw1/overview</li>
</ul>
<h2 id="import-packages">Import Packages</h2>
<p>  在开始任务前首先导入我吗需要使用到的Python库</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Numerical Operations</span><br><span class="hljs-keyword">import</span> math<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-comment"># Reading/Writing Data</span><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> csv<br><br><span class="hljs-comment"># For Progress Bar</span><br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><br><span class="hljs-comment"># Pytorch</span><br><span class="hljs-keyword">import</span> torch <br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset, DataLoader, random_split<br><br><span class="hljs-comment"># For plotting learning curve</span><br><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br></code></pre></td></tr></tbody></table></figure>
<p>  一些库的主要功能：</p>
<ul>
<li><code>tqdm</code>:
用于在循环中显示进度条，以增强用户对程序运行进度的可视化体验。主要功能有<strong>进度条显示、时间估算、定制输出、支持多种数据结构、并发安全.</strong><br>
</li>
<li><code>torch.nn</code>:
用于构建神经网络模型。它提供了各种用于构建神经网络层、损失函数、优化器等的类和函数，使用户能够方便地创建、训练和部署各种类型的神经网络模型。主要功能有<strong>神经网络层的构建、损失函数的定义、优化器、自定义模型、数据转换层、模型的保存和加载.</strong></li>
<li><code>torch.utils.data</code>:
用于处理和管理数据加载、预处理以及批量处理等任务。它提供了一组工具和类，帮助用户有效地加载、处理和传输数据到神经网络模型中，从而方便地进行训练、验证和测试。主要功能有<strong>数据加载与管理、数据预处理、数据批处理、并行加载、迭代加载.</strong><br>
</li>
<li><code>torch.utils.tensorboard</code>:
用于在训练过程中可视化模型训练和性能指标，可以帮助深度学习研究人员和工程师实时监视、分析和优化他们的模型训练过程。主要功能有<strong>训练过程的可视化、模型结构的可视化、嵌入向量的可视化、分布的可视化、图像和音频的可视化.</strong></li>
</ul>
<h2 id="set-random-seed">Set Random Seed</h2>
<p>  由于深度学习的训练过程包含一定的随机性，例如网络参数初始化、随机梯度下降、Dropout等，在学术研究中为了使得结果可以复现，我们通常需要事先设置随机数种子以固定模型的随机性，其代码如下:</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">same_seed</span>(<span class="hljs-params">seed</span>): <br>    <span class="hljs-comment"># Fixes random number generator seeds for reproducibility.</span><br>    torch.backends.cudnn.deterministic = <span class="hljs-literal">True</span><br>    torch.backends.cudnn.benchmark = <span class="hljs-literal">False</span><br>    np.random.seed(seed)<br>    torch.manual_seed(seed)<br>    <span class="hljs-keyword">if</span> torch.cuda.is_available():<br>        torch.cuda.manual_seed(seed)<br>        torch.cuda.manual_seed_all(seed)<br></code></pre></td></tr></tbody></table></figure>
<p>  一些主要函数的功能：</p>
<ul>
<li><code>torch.bankends.cudnn.deterministic</code>:
用于控制在使用CUDA进行深度学习训练时是否启用确定性计算。在深度学习中，训练过程中使用CUDA可以显著加速计算，但由于浮点数的不精确性和优化算法的随机性，相同的代码在不同的运行环境中可能会产生不同的结果。但需要注意的是，启用确定性计算会带来一定的计算效率损失，因为一些优化策略可能会被禁用，从而降低了性能。</li>
<li><code>torch.backends.cudnn.benchmark</code>: 用于控制CuDNN（CUDA
Deep Neural Network
library，NVIDIA深度神经网络库）在使用CUDA加速时是否自动寻找最适合当前硬件环境的优化算法。当设置为True时，将会让程序在开始时花费一点额外时间，为整个网络的每个卷积层搜索最适合它的卷积实现算法，进而实现网络的加速，然而，不同的卷积算法可能在计算精度和数值稳定性方面有微小差异，这可能导致每次前向传播的结果略微不同。当设置为False时，CuDNN不再搜寻最佳算法，而是选择一个固定的卷积算法。这个固定的算法在相同的输入数据和参数情况下产生相同的输出，因为它不受运行时的微小变化影响。<br>
</li>
<li><code>torch.manual_seed()</code>:
用于为CPU设置随机数生成器的种子，从而控制生成的随机数序列。</li>
<li><code>torch.cuda.is_available()</code>:
用于检查当前系统是否支持CUDA，以及是否安装了可用的GPU设备。</li>
<li><code>torch.cuda.manual_seed()</code>:
为GPU设置随机数种子，从而控制生成的随机数序列。</li>
<li><code>torch.cuda.manual_seed_all()</code>:
如果使用的是多GPU模型，其可以设置用于在所有GPU上生成随机数的种子。</li>
</ul>
<h2 id="dataset">Dataset</h2>
<p>  在PyTorch中，我们需要将原始数据集定义为一个Dataset实例，定义Dataset实例的作用是将数据加载和预处理封装成一个可迭代的对象，以便在训练过程中有效地加载和使用数据。其代码如下：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">COVID19Dataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-string">'''</span><br><span class="hljs-string">    x: Features.</span><br><span class="hljs-string">    y: Targets, if none, do prediction.</span><br><span class="hljs-string">    '''</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, x, y=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-keyword">if</span> y <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            self.y = y<br>        <span class="hljs-keyword">else</span>:<br>            self.y = torch.FloatTensor(y)<br>        self.x = torch.FloatTensor(x)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, idx</span>):<br>        <span class="hljs-keyword">if</span> self.y <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            <span class="hljs-keyword">return</span> self.x[idx]<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">return</span> self.x[idx], self.y[idx]<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.x)<br></code></pre></td></tr></tbody></table></figure>
<p>  Dataset类中一些函数的功能：</p>
<ul>
<li><code>__init__()</code>:
Dataset类的构造函数，用于初始化数据集的属性和参数。</li>
<li><code>__getitem__()</code>:
用于根据索引获取数据集中的一个样本。在训练过程中，DataLoader会通过迭代访问数据集，调用__getitem__来获取样本。</li>
<li><code>__len__()</code>:
返回数据集中样本的数量，通常通过获取数据的长度来实现。</li>
</ul>
<h2 id="feature-selection">Feature Selection</h2>
<p>  原始数据集包含众多的特征，但如果将所有的特征作为训练数据，可能会造成训练时间过长，模型过拟合等问题。实际上特征之间往往存在多重共线性，对于这个任务，我们并不需要数量非常庞大的特征，这时我们需要进行特征工程方面的工作，这里不展开解释特征工程的方法，有兴趣可以自行查阅相关资料。总得来说，当我们的数据集包含众多特征时，我们需要保有进行特征工程的意识。在本案例为了简单起见，省略掉了特征筛选的过程，以人为设置的特征作为筛选结果。<br>
</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">select_feat</span>(<span class="hljs-params">train_data, valid_data, test_data, select_all=<span class="hljs-literal">True</span></span>):<br>    <span class="hljs-string">'''Selects useful features to perform regression'''</span><br>    y_train, y_valid = train_data[:,-<span class="hljs-number">1</span>], valid_data[:,-<span class="hljs-number">1</span>]<br>    raw_x_train, raw_x_valid, raw_x_test = train_data[:,:-<span class="hljs-number">1</span>], valid_data[:,:-<span class="hljs-number">1</span>], test_data<br><br>    <span class="hljs-keyword">if</span> select_all:<br>        feat_idx = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(raw_x_train.shape[<span class="hljs-number">1</span>]))<br>    <span class="hljs-keyword">else</span>:<br>        feat_idx = [<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>] <span class="hljs-comment"># <span class="hljs-doctag">TODO:</span> Select suitable feature columns.</span><br>        <br>    <span class="hljs-keyword">return</span> raw_x_train[:,feat_idx], raw_x_valid[:,feat_idx], raw_x_test[:,feat_idx], y_train, y_valid<br></code></pre></td></tr></tbody></table></figure><p></p>
<h2 id="dataloader">Dataloader</h2>
<p>  在定义了Dataset实例后，我们通常需要将Dataset实例传递给Dataloader类。Dataloader是一个迭代器，用于加载和处理训练数据，其可以将数据集划分成小批量的数据，并可以自动进行数据预处理、洗牌和GPU加速等操作。在定义Dataloader时，我们需要确定Training
Data、Testing Data、代码如下：<br>
</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Set seed for reproducibility</span><br>same_seed(config[<span class="hljs-string">'seed'</span>])<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_valid_split</span>(<span class="hljs-params">data_set, valid_ratio, seed</span>):<br>    <span class="hljs-comment">#Split provided training data into training set and validation set</span><br>    valid_set_size = <span class="hljs-built_in">int</span>(valid_ratio * <span class="hljs-built_in">len</span>(data_set)) <br>    train_set_size = <span class="hljs-built_in">len</span>(data_set) - valid_set_size<br>    train_set, valid_set = random_split(data_set, [train_set_size, valid_set_size], generator=torch.Generator().manual_seed(seed))<br>    <span class="hljs-keyword">return</span> np.array(train_set), np.array(valid_set)<br><br><span class="hljs-comment"># train_data size: 2699 x 118 (id + 37 states + 16 features x 5 days) </span><br><span class="hljs-comment"># test_data size: 1078 x 117 (without last day's positive rate)</span><br>train_data, test_data = pd.read_csv(<span class="hljs-string">'./covid.train.csv'</span>).values, pd.read_csv(<span class="hljs-string">'./covid.test.csv'</span>).values<br>train_data, valid_data = train_valid_split(train_data, config[<span class="hljs-string">'valid_ratio'</span>], config[<span class="hljs-string">'seed'</span>])<br><br><span class="hljs-comment"># Print out the data size.</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f"""train_data size: <span class="hljs-subst">{train_data.shape}</span> </span><br><span class="hljs-string">valid_data size: <span class="hljs-subst">{valid_data.shape}</span> </span><br><span class="hljs-string">test_data size: <span class="hljs-subst">{test_data.shape}</span>"""</span>)<br><br><span class="hljs-comment"># Select features</span><br>x_train, x_valid, x_test, y_train, y_valid = select_feat(train_data, valid_data, test_data, config[<span class="hljs-string">'select_all'</span>])<br><br><span class="hljs-comment"># Print out the number of features.</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f'number of features: <span class="hljs-subst">{x_train.shape[<span class="hljs-number">1</span>]}</span>'</span>)<br><br>train_dataset, valid_dataset, test_dataset = COVID19Dataset(x_train, y_train),COVID19Dataset(x_valid, y_valid), COVID19Dataset(x_test)<br><br><span class="hljs-comment"># Pytorch data loader loads pytorch dataset into batches.</span><br>train_loader = DataLoader(train_dataset, batch_size=config[<span class="hljs-string">'batch_size'</span>], shuffle=<span class="hljs-literal">True</span>, pin_memory=<span class="hljs-literal">True</span>)<br>valid_loader = DataLoader(valid_dataset, batch_size=config[<span class="hljs-string">'batch_size'</span>], shuffle=<span class="hljs-literal">True</span>, pin_memory=<span class="hljs-literal">True</span>)<br>test_loader = DataLoader(test_dataset, batch_size=config[<span class="hljs-string">'batch_size'</span>], shuffle=<span class="hljs-literal">False</span>, pin_memory=<span class="hljs-literal">True</span>)  <br></code></pre></td></tr></tbody></table></figure><p></p>
<p>  在这段代码中，我们首先通常前文定义的<code>same_seed()</code>函数固定随机数种子，使得之后的一系列操作的结果可复现。然后我们定义了<code>train_valid_split()</code>函数，这个函数用于将Training
Data进行再次划分，分为真正用于训练的数据与用于检验模型泛化能力的数据，通过<code>valid_ratio</code>参数，我们可以设置train
data和valid
data的划分比例。定义好函数后，我们读取原始csv文件，得到原始的Training
Data和Testing
Data，利用<code>train_valid_split()</code>函数得到划分好的train
data与valid
data。此时，这些数据集仍包含着所有的特征，我们需要通过前文定义的<code>select_feat()</code>函数进行特征筛选，得到正在用于本次任务的数据。最后我们使用这些数据定义Dataset实例，并将定义好的Dataset传递给<code>Dataloader</code>用于之后训练模型。</p>
<p>  <code>Dataloader</code>的一些主要参数及其作用：</p>
<ul>
<li><code>dataset</code>:
指定要加载的Dataset实例，这是DataLoader的必需参数，用于提供数据样本。</li>
<li><code>batch_size</code>:
指定每个批次中包含的样本数量。将数据划分成小批次可以在训练时提高内存的使用效率。</li>
<li><code>shuffle</code>:
设置为True时，在每次返回一批次前会对数据进行随机洗牌。这有助于提高模型的泛化能力。默认值为False。</li>
<li><code>pin_memory</code>：如果在GPU上训练，可以将此参数设置为True，以便在加载数据时将数据置于CUDA固定内存中，从而加速数据传输。</li>
<li><code>drop_last</code>：如果数据样本数量不能整除批次大小，设置为True时，会丢弃最后一个不完整的批次。默认值为False。</li>
<li><code>num_workers</code>：指定用于数据加载的并行线程数。通过并行加载数据可以加快速度，特别是在数据集较大时。</li>
</ul>
<h2 id="neural-network-model">Neural Network Model</h2>
<p>  准备好数据后，我们便需要构建本次任务所用的深度学习模型，这里我构建了一个简单的三层前馈神经网络模型，这个神经网络包含一个输入层，一个隐藏层，一个输出层，其代码如下:<br>
</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">My_Model</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_dim</span>):<br>        <span class="hljs-built_in">super</span>(My_Model, self).__init__()<br>        <span class="hljs-comment"># <span class="hljs-doctag">TODO:</span> modify model's structure, be aware of dimensions. </span><br>        self.layers = nn.Sequential(<br>            nn.Linear(input_dim, <span class="hljs-number">16</span>),<br>            nn.ReLU(),<br>            nn.Linear(<span class="hljs-number">16</span>, <span class="hljs-number">8</span>),<br>            nn.ReLU(),<br>            nn.Linear(<span class="hljs-number">8</span>, <span class="hljs-number">1</span>)<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.layers(x)<br>        x = x.squeeze(<span class="hljs-number">1</span>) <span class="hljs-comment"># (B, 1) -&gt; (B)</span><br>        <span class="hljs-keyword">return</span> x<br></code></pre></td></tr></tbody></table></figure><p></p>
<p>  一些函数及类的主要功能：</p>
<ul>
<li><p><code>nn.Module</code>:
提供了一种组织和管理神经网络组件的方式，使得模型的构建、参数管理和前向传播等过程更加简洁和可控。我们在实际应用中定义的模型<code>My_Model</code>需要继承<code>nn.Module</code>类。<br>
</p></li>
<li><p><code>nn.Sequrntial()</code>:
PyTorch中的一个模型容器，用于按顺序组合多个神经网络模块，从而构建一个序列式的神经网络模型。它可以在不需要自定义模型类的情况下，方便地定义简单的神经网络结构。<br>
</p></li>
<li><p><code>nn.Linear()</code>:
用于定义线性变换（全连接层）。它将输入数据与权重矩阵相乘，并添加一个偏置，从而实现线性变换。nn.Linear()主要用于神经网络中的全连接层，将输入特征映射到输出特征。
  除了使用<code>nn.Linear()</code>进行线性神经网络层，我们还可以根据任务的不同使用诸如卷积神经网络层<code>nn.convXd</code>、循环神经网络层<code>nn.RNN()</code>等。</p></li>
<li><p><code>nn.ReLU()</code>: 用于实现激活函数 ReLU（Rectified Linear
Activation）。ReLU
是深度学习中常用的激活函数之一，它对输入进行非线性变换，将负值变为零，保持正值不变。ReLU
激活函数在神经网络中引入非线性性质，有助于模型学习复杂的特征和表示。<br>
  除了ReLU之外，还有一些常用的激活函数，例如<code>nn.Sigmoid()</code>(Sigmoid函数)、<code>nn.Tanh()</code>(双曲正切激活函数)。我们可以根据训练数据的特点，选择合适的激活函数，或者通过实验确定最佳激活函数。<br>
</p></li>
<li><p><code>forward()</code>:
用于将训练数据通过网络进行前向传播。</p></li>
</ul>
<h2 id="training-loop">Training Loop</h2>
<p>  在准备好数据与模型后，下一步就是训练模型，训练模型的主要流程如下：<br>
</p><figure class="highlight markdown"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs markdown">设置损失函数<br>定义优化器<br>定义tensorboard<br>总训练轮次、当前训练轮次、当前最佳误差、无效训练次数等参数初始化<br><br>for 每一训练轮次 in 总训练轮次：<br><span class="hljs-code">    设置模型为训练模式</span><br><span class="hljs-code">    定义一个空的训练误差列表</span><br><span class="hljs-code">    将训练数据传递给tqdm</span><br><span class="hljs-code">    for 每一批次特征数据、标签数据 in tqdm(训练数据):</span><br><span class="hljs-code">        初始化优化器梯度值</span><br><span class="hljs-code">        将数据移动到GPU中</span><br><span class="hljs-code">        将特征数据输入模型，通过正向传播得到标签数据的预测值</span><br><span class="hljs-code">        通过标签数据的预测值与真实值得到误差</span><br><span class="hljs-code">        误差反向传播，得到误差对于网络参数的梯度</span><br><span class="hljs-code">        利用梯度下降算法更新网络参数</span><br><span class="hljs-code">        step += 1</span><br><span class="hljs-code">        将本批次的误差添加到训练误差列表中</span><br><span class="hljs-code">        自定义训练进度条内容</span><br><span class="hljs-code">    通过对训练误差列表求平均得到这一轮次的平均训练误差</span><br><span class="hljs-code">    将setp与平均训练误差添加到tensorboard中</span><br><span class="hljs-code">    将模型设置为评估模式</span><br><span class="hljs-code">    定义一个空的评估误差列表</span><br><span class="hljs-code">    for 每一批次特征数据、标签数据 in 评估数据:</span><br><span class="hljs-code">        将数据移动到GPU中</span><br><span class="hljs-code">        with 初始化优化器梯度值:</span><br><span class="hljs-code">            将特征数据输入当前模型，通过正向传播得到标签数据的预测值</span><br><span class="hljs-code">            通过标签数据的预测值与真实值得到误差</span><br><span class="hljs-code">        将本批次的误差添加到评估误差列表</span><br><span class="hljs-code">    通过对评估误差列表求平均得到这一轮次的平均评估误差</span><br><span class="hljs-code">    print(当前训练轮次/平均训练误差/平均评估误差)</span><br><span class="hljs-code">    将setp与平均评估误差添加到tensorboard中</span><br><span class="hljs-code">    if 平均评估误差 &lt; 当前最佳误差:</span><br><span class="hljs-code">        将当前最佳误差设置为平均评估误差</span><br><span class="hljs-code">        保存当前模型</span><br><span class="hljs-code">        初始化无效训练次数</span><br><span class="hljs-code">    else:</span><br><span class="hljs-code">        无效训练次数 += 1</span><br><span class="hljs-code">    if 无效训练次数 &gt; 所设置的无效训练次数上限:</span><br><span class="hljs-code">        停止训练</span><br></code></pre></td></tr></tbody></table></figure><p></p>
<p>  这一流程的代码如下：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">trainer</span>(<span class="hljs-params">train_loader, valid_loader, model, config, device</span>):<br><br>    criterion = nn.MSELoss(reduction=<span class="hljs-string">'mean'</span>) <span class="hljs-comment"># Define your loss function, do not modify this.</span><br><br>    <span class="hljs-comment"># Define your optimization algorithm. </span><br>    optimizer = torch.optim.SGD(model.parameters(), lr=config[<span class="hljs-string">'learning_rate'</span>], momentum=<span class="hljs-number">0.9</span>) <br><br>    writer = SummaryWriter() <span class="hljs-comment"># Writer of tensoboard.</span><br><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.isdir(<span class="hljs-string">'./models'</span>):<br>        os.mkdir(<span class="hljs-string">'./models'</span>) <span class="hljs-comment"># Create directory of saving models.</span><br><br>    n_epochs, best_loss, step, early_stop_count = config[<span class="hljs-string">'n_epochs'</span>], math.inf, <span class="hljs-number">0</span>, <span class="hljs-number">0</span><br><br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_epochs):<br>        model.train() <span class="hljs-comment"># Set your model to train mode.</span><br>        loss_record = []<br><br>        <span class="hljs-comment"># tqdm is a package to visualize your training progress.</span><br>        train_pbar = tqdm(train_loader, position=<span class="hljs-number">0</span>, leave=<span class="hljs-literal">True</span>)<br><br>        <span class="hljs-keyword">for</span> x, y <span class="hljs-keyword">in</span> train_pbar:<br>            optimizer.zero_grad()               <span class="hljs-comment"># Set gradient to zero.</span><br>            x, y = x.to(device), y.to(device)   <span class="hljs-comment"># Move your data to device. </span><br>            pred = model(x)             <br>            loss = criterion(pred, y)<br>            loss.backward()                     <span class="hljs-comment"># Compute gradient(backpropagation).</span><br>            optimizer.step()                    <span class="hljs-comment"># Update parameters.</span><br>            step += <span class="hljs-number">1</span><br>            loss_record.append(loss.detach().item())<br>            <br>            <span class="hljs-comment"># Display current epoch number and loss on tqdm progress bar.</span><br>            train_pbar.set_description(<span class="hljs-string">f'Epoch [<span class="hljs-subst">{epoch+<span class="hljs-number">1</span>}</span>/<span class="hljs-subst">{n_epochs}</span>]'</span>)<br>            train_pbar.set_postfix({<span class="hljs-string">'loss'</span>: loss.detach().item()})<br><br>        mean_train_loss = <span class="hljs-built_in">sum</span>(loss_record)/<span class="hljs-built_in">len</span>(loss_record)<br>        writer.add_scalar(<span class="hljs-string">'Loss/train'</span>, mean_train_loss, step)<br><br>        model.<span class="hljs-built_in">eval</span>() <span class="hljs-comment"># Set your model to evaluation mode.</span><br>        loss_record = []<br>        <span class="hljs-keyword">for</span> x, y <span class="hljs-keyword">in</span> valid_loader:<br>            x, y = x.to(device), y.to(device)<br>            <span class="hljs-keyword">with</span> torch.no_grad():<br>                pred = model(x)<br>                loss = criterion(pred, y)<br><br>            loss_record.append(loss.item())<br>            <br>        mean_valid_loss = <span class="hljs-built_in">sum</span>(loss_record)/<span class="hljs-built_in">len</span>(loss_record)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f'Epoch [<span class="hljs-subst">{epoch+<span class="hljs-number">1</span>}</span>/<span class="hljs-subst">{n_epochs}</span>]: Train loss: <span class="hljs-subst">{mean_train_loss:<span class="hljs-number">.4</span>f}</span>, Valid loss: <span class="hljs-subst">{mean_valid_loss:<span class="hljs-number">.4</span>f}</span>'</span>)<br>        writer.add_scalar(<span class="hljs-string">'Loss/valid'</span>, mean_valid_loss, step)<br><br>        <span class="hljs-keyword">if</span> mean_valid_loss &lt; best_loss:<br>            best_loss = mean_valid_loss<br>            torch.save(model.state_dict(), config[<span class="hljs-string">'save_path'</span>]) <span class="hljs-comment"># Save your best model</span><br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">'Saving model with loss {:.3f}...'</span>.<span class="hljs-built_in">format</span>(best_loss))<br>            early_stop_count = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">else</span>: <br>            early_stop_count += <span class="hljs-number">1</span><br><br>        <span class="hljs-keyword">if</span> early_stop_count &gt;= config[<span class="hljs-string">'early_stop'</span>]:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">'\nModel is not improving, so we halt the training session.'</span>)<br>            <span class="hljs-keyword">return</span><br></code></pre></td></tr></tbody></table></figure>
<p>  训练流程中一些函数的作用及参数:</p>
<ul>
<li><code>nn.MSELoss()</code>: PyTorch
中的一个损失函数模块，用于计算均方误差损失。   常用的一些损失函数:
交叉熵损失<code>nn.CrossEntropyLoss()</code>，负对数似然损失<code>nn.NLLLoss()</code>，KL散度损失<code>nn.KLDivLoss()</code>等，可以更具任务特点与所用模型选择合适的损失函数，例如均方误差损失多用于回归任务，交叉熵损失多用于分类任务，KL散度损失一般用于GAN模型。<br>
</li>
<li><code>torch.optim.SGD()</code>: 用于实现随机梯度下降（Stochastic
Gradient Descent，SGD）优化算法。SGD
是深度学习中最基本和常用的优化算法之一，用于调整模型的参数以最小化损失函数。其重要参数:
<ul>
<li><code>params</code>：这是一个模型参数的可迭代对象，指定了需要进行优化的参数。一般通过<code>model.parameters()</code>来获取模型中的参数列表。</li>
<li><code>lr</code>：学习率，控制参数更新的步长。它决定了每次参数更新的幅度，过大可能导致不稳定的训练，过小可能导致收敛速度缓慢。<br>
</li>
<li><code>momentum</code>: 动量，用于加速梯度下降过程。设置一个介于 0 到
1
之间的值，代表在更新参数时考虑前一次的动量。较大的动量值可以帮助跳出局部最小值。</li>
</ul></li>
</ul>
<p>  除开基础的SGD优化方法，深度学习中还有Adam<code>torch.optim.Adam()</code>，RMSprop<code>torch.optim.RMSprop()</code>，Adagrad<code>torch.optim.Adagrad()</code>等优化算法，它们各种适应不同的数据特点。想进一步了解深度学习中的优化算法可以查阅相关资料。</p>
<p>  完成模型训练的流程后，下一步便是设置训练步骤中所需要的超参数。</p>
<h2 id="configurations">Configurations</h2>
<p>  设置我们在整个任务中所需要用到的参数：<br>
</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">device = <span class="hljs-string">'cuda'</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">'cpu'</span><br>config = {<br>    <span class="hljs-string">'seed'</span>: <span class="hljs-number">5201314</span>,      <span class="hljs-comment"># random seed</span><br>    <span class="hljs-string">'select_all'</span>: <span class="hljs-literal">True</span>,   <span class="hljs-comment"># Whether to use all features.</span><br>    <span class="hljs-string">'valid_ratio'</span>: <span class="hljs-number">0.2</span>,   <span class="hljs-comment"># validation_size = train_size * valid_ratio</span><br>    <span class="hljs-string">'n_epochs'</span>: <span class="hljs-number">3000</span>,     <span class="hljs-comment"># Number of epochs.            </span><br>    <span class="hljs-string">'batch_size'</span>: <span class="hljs-number">256</span>, <br>    <span class="hljs-string">'learning_rate'</span>: <span class="hljs-number">1e-5</span>,              <br>    <span class="hljs-string">'early_stop'</span>: <span class="hljs-number">400</span>,    <span class="hljs-comment"># If model has not improved for this many consecutive epochs, stop training.     </span><br>    <span class="hljs-string">'save_path'</span>: <span class="hljs-string">'./models/model.ckpt'</span>  <span class="hljs-comment"># Your model will be saved here.</span><br>}<br></code></pre></td></tr></tbody></table></figure><p></p>
<h2 id="start-training">Start training!</h2>
<p>  完事具备，开始训练我们的模型吧！<br>
</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">model = My_Model(input_dim=x_train.shape[<span class="hljs-number">1</span>]).to(device) <span class="hljs-comment"># put your model and data on the same computation device.</span><br>trainer(train_loader, valid_loader, model, config, device)<br></code></pre></td></tr></tbody></table></figure><p></p>
<p>  由于深度学习模型的参数量一般较大，训练可能会花费一定的时间，待训练完成后我们便得到了已更新好参数的神经网络模型。</p>
<h2 id="plot-learning-curves-with-tensorboard">Plot learning curves with
tensorboard</h2>
<p>  通过使用<code>tensorboard</code>，我们可以得到损失曲线与学习曲线，便于我们更好地理解模型训练的过程。<br>
</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">%reload_ext tensorboard<br>%tensorboard --logdir=./runs/<br></code></pre></td></tr></tbody></table></figure><p></p>
<h2 id="testing">Testing</h2>
<p>  最后，我们可以将Testing
Data输入到已经更新好参数的模型，得到相应标签数据的预测值，我们可以通过比较真实值与预测值之间的差异评价模型训练的结果。<br>
</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">test_loader, model, device</span>):<br>    model.<span class="hljs-built_in">eval</span>() <span class="hljs-comment"># Set your model to evaluation mode.</span><br>    preds = []<br>    <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> tqdm(test_loader):<br>        x = x.to(device)                        <br>        <span class="hljs-keyword">with</span> torch.no_grad():                   <br>            pred = model(x)                     <br>            preds.append(pred.detach().cpu())   <br>    preds = torch.cat(preds, dim=<span class="hljs-number">0</span>).numpy()  <br>    <span class="hljs-keyword">return</span> preds<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">save_pred</span>(<span class="hljs-params">preds, file</span>):<br>    <span class="hljs-string">''' Save predictions to specified file '''</span><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(file, <span class="hljs-string">'w'</span>) <span class="hljs-keyword">as</span> fp:<br>        writer = csv.writer(fp)<br>        writer.writerow([<span class="hljs-string">'id'</span>, <span class="hljs-string">'tested_positive'</span>])<br>        <span class="hljs-keyword">for</span> i, p <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(preds):<br>            writer.writerow([i, p])<br><br>model = My_Model(input_dim=x_train.shape[<span class="hljs-number">1</span>]).to(device)<br>model.load_state_dict(torch.load(config[<span class="hljs-string">'save_path'</span>]))<br>preds = predict(test_loader, model, device) <br>save_pred(preds, <span class="hljs-string">'pred.csv'</span>)      <br></code></pre></td></tr></tbody></table></figure><p></p>
<p>  预测的结果保存在<code>pred.csv</code>文件中。</p>
<h2 id="reference">Reference</h2>
<p>https://www.bilibili.com/video/BV1Wv411h7kN?p=11&amp;vd_source=234cf2ac075a1558881a6956450ddf89</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="category-chain-item">深度学习</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>深度学习-1.使用Pytorch搭建深度学习模型的基本框架——以COVID-19 Cases Prediction为例</div>
      <div>http://example.com/2023/08/14/深度学习-1.使用Pytorch搭建深度学习模型的基本框架——以COVID-19 Cases Prediction为例/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>喵老师</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2023年8月14日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2023/08/27/%E7%9F%A9%E9%98%B5%E5%88%86%E6%9E%90-3-%E5%9F%BA%E4%B8%8E%E5%9D%90%E6%A0%87/" title="矩阵分析-3.基与坐标">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">矩阵分析-3.基与坐标</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2023/08/08/%E6%9C%80%E4%BC%98%E5%8C%96%E7%90%86%E8%AE%BA-2-%E4%BB%BF%E5%B0%84%E9%9B%86%E4%B8%8E%E4%BB%BF%E5%B0%84%E5%8C%85/" title="最优化理论-2.仿射集与仿射包">
                        <span class="hidden-mobile">最优化理论-2.仿射集与仿射包</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
  <div id="valine"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#valine', function() {
      Fluid.utils.createScript('https://lib.baomitu.com/valine/1.5.1/Valine.min.js', function() {
        var options = Object.assign(
          {"appId":"OLzAG6UdDYLLDlQvyrFhe7ho-gzGzoHsz","appKey":"IuY7HMC7xJw1qmdlkBlrfMRq","path":"window.location.pathname","placeholder":null,"avatar":"retro","meta":["nick","mail","link"],"requiredFields":[],"pageSize":10,"lang":"zh-CN","highlight":false,"recordIP":false,"serverURLs":"","emojiCDN":null,"emojiMaps":null,"enableQQ":false},
          {
            el: "#valine",
            path: window.location.pathname
          }
        )
        new Valine(options);
        Fluid.utils.waitElementVisible('#valine .vcontent', () => {
          var imgSelector = '#valine .vcontent img:not(.vemoji)';
          Fluid.plugins.imageCaption(imgSelector);
          Fluid.plugins.fancyBox(imgSelector);
        })
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        总访问量 
        <span id="busuanzi_value_site_pv"></span>
         次
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        总访客数 
        <span id="busuanzi_value_site_uv"></span>
         人
      </span>
    
    
  
</div>

  
  
    <!-- 备案信息 ICP for China -->
    <div class="beian">
  <span>
    <a href="http://beian.miit.gov.cn/" target="_blank" rel="nofollow noopener">
      京ICP证123456号
    </a>
  </span>
  
    
      <span>
        <a
          href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=12345678"
          rel="nofollow noopener"
          class="beian-police"
          target="_blank"
        >
          
            <span style="visibility: hidden; width: 0">|</span>
            <img src="/img/police_beian.png" srcset="/img/loading.gif" lazyload alt="police-icon"/>
          
          <span>京公网安备12345678号</span>
        </a>
      </span>
    
  
</div>

  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>
